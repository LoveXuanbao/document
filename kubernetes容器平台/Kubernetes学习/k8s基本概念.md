# 前言

## 有了Docker，为什么还要用K8s

裸容器的问题：

1. 宿主机宕机容器无法自动恢复；
2. 程序级健康检查不到位；
3. 程序的扩容、部署、回滚和更新不够灵活；
4. 端口问题并未得到解决。

## 什么是容器编排？

1. 轻松管理成千上万的业务容器；
2. 全自动容灾机制；
3. 全自动扩缩容、回滚；
4. 原生支持服务器发现和负载均衡；
5. 更加灵活方便的健康检查；

## 云原生基石-k8s

kuberentes是谷歌开发的第三个容器管理系统，提供了资源调度、扩容缩容、服务发现、存储编排、自动部署和回滚，并且具天生具有高可用、负载均衡、故障自动恢复等功能的“生态系统”，目前已经成为云原生（CNCF）领域的标准。

# 一、K8s架构解析

![image-20230825165156959](https://niuzhan-1306014148.cos.ap-beijing.myqcloud.com/Typora/image-20230825165156959.png)

# 二、控制节点组件解析

## APIServer

`APIServer` 是整个集群的控制中枢，提供集群中各个模块之间的数据交换，并将集群状态和信息存储到分布式键-值（key - value）存储系统 `ETCD` 集群中。同时它也是集群管理、资源配额、提供完备的集群安全机制的入口，为集群各类资源对象提供增删嘎查以及 watch 的 REST API 接口。

## Controller Manager

`Controller Manager`是集群状态管理器，以保证 `Pod` 或其他资源达到期望值。当集群中某个 `Pod` 的副本数或其他资源因故障和错误导致无法正常运行，没有达到设定的值时，`Controller Manager` 会尝试自动修复并使其达到期望状态

## Scheduler

`Scheduler` 是集群 `Pod` 的调度中心，主要是通过调度算法将 `Pod` 分配到最佳的 `Node` 节点，它通过 `APIServer` 监听所有 `Pod` 的状态，一旦发现新的未被调度到任何 `node` 节点的 `Pod` （PodSpec.NodeName为空），就会根据一系列策略选择最佳节点进行调度

## ETCD

`etcd` 是由 `CoreOS` 开发，用于可靠的存储集群的配置数据，是一种持久性、轻量型、分布式的键-值（key - value）数据存储组件，作为 `Kubernetes` 集群的持久化存储系统

# 三、工作节点组件解析

## Kubelt

`Kubelet` 是负责与 `Master` 通信协作，管理该节点上的 `Pod` ，对容器进行健康检查及监控，同时负责上报节点和节点上面的 `Pod` 的状态

## Kube-proxy

`Kube-proxy` 是负责各 `Pod` 之间的通信和负载均衡，将指定的流量分发到后端正确的机器上

## Runtime

容器运行时，负责容器的管理

## CoreDNS

`CoreDNS` 用户 `Kubernetes` 集群内部 `Service` 的解析，可以让 `Pod` 把 `Servoce` 名称解析成 `Service的IP` ，然后通过 `Service的IP` 进行连接到对应的应用上

## Calico

`Calico` 是符合 `CNI标准` 的一个网络插件，它负责给每个 `Pod` 分配一个 `不会重复的IP` ，并且把每个节点当作一个“路由器”，这样一个节点的 `Pod` 就可以通过 `IP地址` 访问到其他节点的 `Pod` 

## 



