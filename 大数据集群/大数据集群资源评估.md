

目前我们在售卖zeta时, 不能给用户合理的资源评估, 经常集群资源不满足用户真实数据量处理要求的情况下, 直接部署zeta集群,导致运行中服务出现各种问题,后台人员协助救火, 导致客户不满意, 研发人员精力被分散, 交付效率低下。以下就资源评估, 给出一个较为合理的评估手段, 做到申请资源的时候心中有数

## 集群规模评估

需要搭建多少节点的hadoop集群？回答这个问题考虑的因素比较多：预算？数据量？计算资源？

可以先按照数据量来评估数据规模，估计一下每天的数据增量？保存数据的周期是多少？有没有冷数据方案？

假设每天增长的数据为600G、3副本存储，以一年规划为例,大概存储为600G * 3 *360天=633T, 再考虑增加50%的预留，考虑未来数据增长的趋势，考虑应用计算等空间需求。为节省空间可考虑压缩存储（大概可以节省70%空间）。

同时考虑一定冗余量，如果集群一部分节点不可用也要保证业务正常使用（根据集群规模评估冗余比例）。

然后结合节点硬件规划和预算，确定集群规模。假如我们需要650T存储，可以采用30台12 x 2TB的存储配置或者 60台6 x 2TB配置，但是节点数量翻翻，这样同样可以满足存储需求。需要注意的是，这种变化实际上增加了计算能力，但是，需要增加更多的电力、制冷、机架空间、网络端口密度。所以这是一种权衡，根据实际的需求考虑。

### 预估公式

预估客户的已有数据old_data,每天数据量为data, hadoop做3副本存储, 全年总的数据量为total_data = data * 3 * 360, 除了原始数据存储, 还需要考虑中间计算数据、 结果数据等,再考虑到冗余存储等,根据以往经验,总的数据磁盘存储大小为总预估数据量的1倍左右才是安全的.

数据盘的大小(单位T)`data_disk= (old_data  + data * 360) * 3 * 2`

服务器数量`server= data_disk/ (2T * 12) 或者 data_disk/(2T * 10)`,  2T为单个数据磁盘的大小, 10和12为单台服务器的数据磁盘数量,磁盘数量可根据实际情况调整,最少不低于8个





## 计算资源评估

需要多少计算资源不是特别好评估，以下是根据预估数据量对计算资源做评估, 后面随业务规模和应用发展再考虑扩展。

正式环境每个节点建议至少有64GB的内存, 物理CPU核不低于6核, 虚拟CPU不低于12核, 按照服务器部署的每个组件内存相加,计算内存总和, 适当增加服务器内存及CPU配置, 内存与虚拟核数比例建议不低于6:1



### 计算内存预估

根据公司ad和wd的经验, 计算内存至少为每日数据增量的4倍, total_memory=data * 4



## 评估举例



假设用户每天的数据量为500G, 那么总的数据盘大小为: 500G * 3 * 360 * 2 / 1024 = 1055T

一年需要的存储服务器数量为: 1055T/(2T * 12) = 44台

根据1055T的全年数据量, namenode_java_heapsize_GB = (1055 * 1024 * 1024 / 384 ) * 20 / 1000000 = 58G

主备namenode服务器至少需要的内存: 58G+8G + 2G + 2G + 2G = 72G

计算节点总内存为 : 500G * 4 = 2000G, 

一年需要的计算服务器的数量为 : 2000G/64G = 32台或者2000G/128G=16台

存储和计算复用, 那么总共需要44台 64G服务器 + 2台72G  namenode服务器

## 组件内存预估

### namenode

[按照业内通用的标准](https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_nn_memory_config.html#concept_efv_5pc_r5), 每100万个block, namenode和datanode需要1G的内存, 按照128M一个block, 理论的block数量是`block_num= data_disk/384M`。

但是根据登月现场的估算, 小文件较多, 基本上block数量是理论值的20倍, 那么预估的namenode内存应该是`namenode_java_heapsize_GB=(block_num * 20/1000000) ` 

主备namenode节点的内存 = namenode_java_heapsize_GB + <8GB for the OS> + other processes(zookeeper,jn,RM一般每个进程2G-4G)

### datanode

每个节点200万block内, 默认2G内存, 每增加100万block, 增加1G内存

### hive

单个HiveServer2内存不建议超过16G, 否则java的垃圾回收会影响正常的处理, 如果并发连接数超过40个,请增加hiveserver2的数量。Beeline CLI默认2G内存。

| Number of Concurrent Connections | HiveServer2 Heap Size Minimum Recommendation | Hive Metastore Heap Size Minimum Recommendation |
| -------------------------------- | -------------------------------------------- | ----------------------------------------------- |
| 41-80 connections                | 16-24 GB                                     | 16-24 GB                                        |
| 21-40 connections                | 12-16 GB                                     | 12-16 GB                                        |
| 11-20 connections                | 6-12 GB                                      | 10-12 GB                                        |
| 2-10 connections                 | 4-6 GB                                       | 4-10 GB                                         |
| Single connection                | 2 GB                                         | 4 GB                                            |

### impala 

Impala Daemon 计算内存:最低16G, 

Impala Daemon JVM内存: 2G-4G

Catalog Server JVM内存:2G-4G

### yarn

Job History Server  JVM内存:1G

NodeManager JVM内存:2G

ResourceManager JVM内存: 2G- 4G,根据job的数量、nodemanager数量、保留已完成任务数量适当调整

### hbase

master JVM内存

- 100-10,000 regions: 4 GB
- 10,000 or more regions with 200 or more Region Servers: 8 GB
- 10,000 or more regions with 300 or more Region Servers: 12 GB

Region Server JVM内存:8G

## 自研产品内存建议

| 产品服务       | 最小内存                                                     | 共享CPU |
| -------------- | ------------------------------------------------------------ | ------- |
| 数据管理       | 2G                                                           | 4核     |
| 自助分析       | 2G                                                           | 4核     |
| 实时引擎       | 2G                                                           | 4核     |
| 多维建模       | 2G                                                           | 4核     |
| 安全中心       | 2G                                                           | 4核     |
| 数据集成master | 2G                                                           | 4核     |
| 数据集成worker | 2G                                                           | 4核     |
| 数据集成runner | 最低2G, 根据并发集成的表数量及大小调整, 例如收集器同时集成10个表, 每个表100MB, 那么需要增加10 * 100MB的内存 | 4核     |
| 任务调度api    | 2G                                                           | 4核     |
| 任务调度alert  | 2G                                                           | 4核     |
| 任务调度logger | 2G                                                           | 4核     |
| 任务调度master | 最低4G，根据并发调度的任务数调整，默认100个任务并发，每增加一个并发增加10MB，例如增加到200个并发，在默认的基础上又增加了100个并发，需要增加10*100MB内存 | 4核     |
| 任务调度worker | 最低4G，根据并发调度的任务数调整，默认100个任务并发，每增加一个并发增加10MB，例如增加到200个并发，在默认的基础上又增加了100个并发，需要增加10*100MB内存 | 4核     |

## 硬件规格参考

https://gitlab.gridsum.com/zeta/project/-/wikis/uploads/c2ae4f361006eb7e9a9d77aab990aa29/20210421%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83%E5%BB%BA%E8%AE%AE.docx





参考链接

- 华为云,https://support.huawei.com/enterprise/zh/cloud-computing/fusioninsight-hd-pid-21110924

- 星环,https://docs.transwarp.cn/#/documents-support/docs-detail/document/TDH-OPS/7.0/010InstallManual?docType=docs%3Fcategory%3DTDH%26index%3D0&docName=TDH%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C

- cloudera,https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_hardware_requirements.html

  