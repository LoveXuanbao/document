# 什么是数据库

- 数据库（database）是按照数据结构来组织、存储和管理数据的仓库，提供很强大的数据处理能力，能够存储大量的数据。
- 每个数据库都有一个或多个不同的`API`用于创建，访问，管理，搜索和复制所保存的数据。

- 我们也可以将数据存储在文件中，但是在文件中读写数据速度相对较慢
- 所以，现在我们使用关系型数据库管理系统来存储和管理的大数据量。所谓的关系型数据库，是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。

## RDBMS 术语

- 数据库: 数据库是一些关联表的集合。

- 数据表: 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。

- 列: 一列(数据元素) 包含了相同类型的数据, 例如邮政编码的数据。

- 行：一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。

- 冗余：存储两倍数据，冗余降低了性能，但提高了数据的安全性。

- 主键：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。

- 外键：外键用于关联两个表。

- 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。

- 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。

- 参照完整性: 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。

# MySQL数据库

MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL
  是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。

- `MySQL` 是开源的，所以你不需要支付额外的费用。
- `MySQL` 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。
- `MySQL` 使用标准的 SQL 数据语言形式。
- `MySQL` 可以运行于多个系统上，并且支持多种语言。这些编程语言包括 C、C++、Python、Java、Perl、PHP、Eiffel、Ruby 和 Tcl 等。
- `MySQL` 对PHP有很好的支持，PHP 是目前最流行的 Web 开发语言。
- `MySQL` 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4GB，64 位系统支持最大的表文件为8TB。
- `MySQL` 是可以定制的，采用了 GPL 协议，你可以修改源码来开发自己的 MySQL 系统。

# Mysql优点及特点

- `MySQL` 性能卓越服务稳定，很少出现异常宕机，但是单张表的数据建议不要超过600w条，单张表最好不要超过3-4G，如果数据超出太多，MySQL性能急剧下降。
- `MySQL` 免费，开放源代码且无版权制约，自主性强、使用成本低。
- `MySQL` 历史悠久、社区及用户非常活跃，遇到问题，可以很快获取到帮助。
- `MySQL` 软件体积小，安装使用简单，并且易于维护，安装及维护成本低。
- `MySQL` 支持多种操作系统，提供多种api几口，支持多种开发语言。
- `MySQL` 口碑效应好，是LAMP、LNMP架构的优先选择



# MySQL 安装

## CentOS 6.X 安装

1. 安装

```shell
yum install -y mysql-server mysql
```

2. 启动

```shell
service mysqld start
```



## CentOS 7.X 安装

1. 下载并安装MySQL官方的yum reoisitory

```shell
wget http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm
```

2. 使用上面的命令就直接下载了mysql的yum reoisitory，然后直接yum安装

```shell
yum install -y mysql57-community-release-el7-10.noarch.rpm
```

3. 之后就可以开始安装MySQL服务

```shell
yum install -y mysql-community-server
```

4. 启动

```shell
systemctl start mysqld
```

# MySQL 数据目录

数据目录：`/var/lib/mysql`

# MySQL存储引擎

- 存储引擎其实就是对于数据库文件的一种存取机制，如何实现存储数据，如何为存储的数据建立索引以及如何更新，查询数据等技术实现的方法。
- MySQL中的数据用各种不同的技术存储在文件（或内存）中，这些技术中的每一种技术都使用不同的存储机制，索引技巧，锁定水平并且最终提供广泛的不同功能和能力。在MySQL中将这些不同的技术及配套的相关功能称为存储引擎。
- MySQL中常用的存储引擎分别是：MyISAM存储引擎、InnoDB存储引擎、MEMORY存储引擎、ARCHIVE存储引擎。
- MySQL 5.5之前的存储引擎是`MyISAM`，5.5版本之后的默认引擎是`InnoDB`
- `.frm文件`：存储数据表的框架结构，文件名与表明相同，每个表对应一个同名的frm文件，与操作系统和存储引擎无关，即不管MySQL运行在何种操作系统上，使用何种存储引擎，都有这个文件。除了必有的`.frm`文件，根据MySQL所使用的存储引擎的不同，存储引擎会创建各自不同的数据库文件。

## MySQL中查看存储引擎

1. `show engines;`  查看MySQL所支持的存储引擎，以及从中得到MySQL默认的存储引擎。

![](https://niuzhan-1306014148.cos.ap-beijing.myqcloud.com/Typora/image-20200517145512726.png)

2. `show create table tbl_name;` 查看某个表的存储引擎。以及创建表的语句

## MyISAM 存储引擎

该引擎基于ISAM数据库引擎，除了提供ISAM里所没有的索引和字段管理等大量功能，MyISAM还使用一种表格锁定的机制来优化多个并发的读写速度，但是需要经常运行`OPTIMIZE TABLE`命令，来恢复被更新机制所浪费的空间，否则碎片也会随之增加，最终影响数据访问性能。MyISAM还有一些有用的扩展，例如用来修复数据库文件的`MyISAMChk`工具和用来恢复浪费空间的`MyISAMPack`工具。MyISAM强调了快速读取操作，主要用于高负载的select，这可能也是MySQL深受Web开发的主要原因：在Web开发中进行的大量数据操作都是读取操作，所以大多数虚拟主机提供商和Internet平台提供商（Internet Presence Provider，IPP）只允许使用MyISAM格式。

### MyISAM存储引擎数据库文件类型

- **.MYD文件：**即MY Data，表数据文件
- **.MYI文件：**即MY Index，索引文件
- **.log文件：**日志文件

### MyISAM类型的表支持三种不同的存储结构：静态型、动态型、压缩型。

- 静态型：指定义的表列的大小是固定（即不含有：xblob、xtext、varchar等长度可变的数据类型），这样MySQL就会自动使用静态MyISAM格式。使用静态格式的表的性能比较高，因为在维护和访问以预定格式存储数据时需要的开销很低；但这种高性能是以空间为代价换来的，因为在定义的时候是固定的，所以不管列中的值有多大，都会以最大值为准，占据了整个空间。
- 动态型：如果列（即使只有一列）定义为动态的（xblob, xtext, varchar等数据类型），这时MyISAM就自动使用动态型，虽然动态型的表占用了比静态型表较少的空间，但带来了性能的降低，因为如果某个字段的内容发生改变则其位置很可能需要移动，这样就会导致碎片的产生，随着数据变化的增多，碎片也随之增加，数据访问性能会随之降低。
  对于因碎片增加而降低数据访问性这个问题，有两种解决办法：
  a、尽可能使用静态数据类型；
  b、经常使用optimize table table_name语句整理表的碎片，恢复由于表数据的更新和删除导致的空间丢失。如果存储引擎不支持 optimize table table_name则可以转储并 重新加载数据，这样也可以减少碎片；
- 压缩型：如果在数据库中创建在整个生命周期内只读的表，则应该使用MyISAM的压缩型表来减少空间的占用。

### MyISAM优缺点

- 优点：占用空间小，读写速度非常快，使用表锁。
- 缺点：不支持事务的完整性，并发性比较低。

## InnoDB存储引擎

- InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键。

- innodb为MySQL提供了具有提交、回滚和崩溃恢复能力的事务安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在`select`语句中提供了一个类似`oracle`的非锁定都。这些功能增加了多用户部署和性能。在SQL查询中，可以自由的将innodb类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合。

- InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上

- innodb支持自增长列（auto_increment）,自增长列的值不能为空，如果在使用的时候为空的话就会进行自动存现有的值开始增值，如果有但是比现在的还大，则就保存这个值。

- innodb存储引擎支持外键（foreign key） ,外键所在的表称为子表而所依赖的表称为父表。

- innodb存储引擎最重要的是支持事务，以及事务相关联功能。

- innodb存储引擎支持mvcc的行级锁。

- innodb存储引擎索引使用的是B+Tree

### InnoDB存储引擎数据库文件

使用InnoDB存储引擎，MySQL将在数据目录下创建一个名为`ibdata1`的自动扩展数据文件，以及两个名为`ib_logfile0`和`ib_logfile1`的日志文件

- `.frm`：表结构
- `ibdata1`：存储的是所有innodb引擎的表数据和表索引
- `ib_logfile0`、`ib_logfile1`：这两个文件就是事务日志

### InnoDB存储引擎优缺点

- 优点：提供良好的事务处理、崩溃修复能力和 并发控制
- 缺点：读写效率较差，占用的数据库空间相对较大



# MySQL事务

![](https://niuzhan-1306014148.cos.ap-beijing.myqcloud.com/Typora/image-20200518160142580.png)

## 什么是事务

数据库几乎是所有系统的核心模块，它将数据有条理地保存在储存介质(磁盘）中，
并在逻辑上，将数据以结构化的形态呈现给用户。支持数据的增、删、改、查，并在过程中保障数据的正确且可靠。

要做到这点并非易事，常见的例子就是银行转账，A账户给B账户转账一个亿(T1)，买一块地盖房子。在这种交易的过程中，有几个问题值得思考：

- 如何**同时保证**上述交易中，A账户总金额减少一个亿，B账户总金额增加一个亿？ A
- A账户如果同时在和C账户交易(T2)，如何让这两笔交易互不影响？ I
- 如果交易完成时数据库突然崩溃，如何保证交易数据成功保存在数据库中？ D
- 如何在支持大量交易的同时，保证数据的合法性(没有钱凭空产生或消失) ？ C

要保证交易正常可靠地进行，数据库就得解决上面的四个问题，这也就是`事务`诞生的背景，它能解决上面的四个问题，对应地，它拥有四大特性：

- 原子性（**A**tomicity）: 事务`要么全部完成，要么全部取消`。 如果事务崩溃，状态回到事务之前（事务回滚）。
- 隔离性（**I**solation）: 如果2个事务 T1 和 T2 同时运行，事务 T1 和 T2 最终的结果是相同的，不管 T1和T2谁先结束。
- 持久性（**D**urability）: 一旦事务提交，不管发生什么（崩溃或者出错），数据要保存在数据库中。
- 一致性（**C**onsistency）: 只有合法的数据（依照关系约束和函数约束）才能写入数据库。

## ACID

接下来详细地了解这四大特性：

- **原子性**，确保不管交易过程中发生了什么意外状况（服务器崩溃、网络中断等），不能出现A账户少了一个亿，但B账户没到帐，或者A账户没变，但B账户却凭空收到一个亿（数据不一致）。A和B账户的金额变动要么同时成功，要么同时失败(保持原状)。
- **隔离性**，如果A在转账1亿给B（T1），同时C又在转账3亿给A（T2），不管T1和T2谁先执行完毕，最终结果必须是A账户增加2亿，而不是3亿，B增加1亿，C减少3亿。
- **持久性**，确保如果 T1 刚刚提交，数据库就发生崩溃，T1执行的结果依然会保持在数据库中。
- **一致性**，确保钱不会在系统内凭空产生或消失， 依赖原子性和隔离性。

可以看出，原子性、隔离性、一致性的根本问题，是不同的事务同时对同一份数据(A账户)进行`写操作`(修改、删除、新增)，如果事务中都只是读数据的话，那么它们可以随意地同时进行，反正读到的数据都是一样的。

如果，几个互不知晓的事务在同时修改同一份数据，那么很容易出现后完成的事务覆盖了前面的事务的结果，导致不一致。 事务在最终提交之前都有可能会回滚，撤销所有修改：

1. 如果T1事务修改了A账户的数据，
2. 这时T2事务读到了更新后的A账户数据，并进行下一步操作，
3. 但此时T1事务却回滚了，撤销了对A账户的修改，
4. 那么T2读取到的A账户数据就是非法的，这会导致数据不一致

这些问题都是事务需要避免的。

## 如何保证原子性

```shell
begin; -- 开始一个事务
update table set A = A - 1亿; -- 伪sql，仅作示意
update table set B = B + 1亿;
-- 其他读写操作
commit; -- 提交事务
```

要保证上面操作的原子性， 就得等`begin`和`commit`之间的操作全部成功完成后，才将结果统一提交给数据库保存，如果途中任意一个操作失败，就撤销前面的操作，且操作不会提交数据库保存,这样就保证了`同生共死`。

## 如何保证了隔离性

原子性的问题解决了，但是如果有另外的事务在同时修改数据A怎么办呢？ 虽然可以保证事务的同生共死，但是数据一致性会被破坏。 此时需要引入数据的隔离机制，确保同时只能有一个事务在修改A，一个修改完了，另一个才来修改。 这需要对数据A加上互斥锁：

- 先获得了锁，然后才能修改对应的数据A
- 事务完成后释放锁，给下一个要修改数据A的事务
- 同一时间，只能有一个事务持有数据A的互斥锁
- 没有获取到锁的事务，需要等待锁释放

以上面的事务为例，称作T1，T1在更新A的时候，会给A加上互斥锁，保证同时只能有一个事务在修改A。 那么这个锁什么时候释放呢？ 当A更新完毕后，正在更新B时(T1还没有提交)，有另外一个事务T2想要更新A，它能获取到A的互斥锁吗？

答案是不能， 如果T1在更新完A后，就释放了互斥锁，此时T2获取到T1的最新值，并做修改， 如果一且正常，则万事大吉。 但是如果在T2更新A时，T1因为后面的语句执行失败而回滚了呢？

1. 此时T1会撤销对A的修改，
2. T2得到的A数据就是脏数据，更新脏数据就会导致数据不一致。

所以，在事务中更新某条数据获得的互斥锁，**只有在事务提交或失败之后才会释放**，在此之前，其他事务是只能读，不能写这条数据的。

这就是隔离性的关键，针对隔离性的强度，有以下四的级别

- 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的"世界", 串行执行。
- 可重复读（Repeatable read，MySQL默认模式）：如果一个事务成功执行并且添加了新数据(事务提交)，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。
- 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。
- 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫脏读（dirty read）。

接下来详细解释，假设有下面两个事务**同时执行**：

```shell
begin; -- 事务1
insert into table1 (somevaue); -- 随意写的伪sql
update table2 set aa = aa + 1 where id = 1;
commit;
begin; -- 事务2
select count(*) from table1; -- 第一次读count
select aa from table2 where id = 1; -- 第一次读aa
-- 假设在这个点 事务1成功提交
select count(*) from table1; -- 第二次读count
select aa from table2 where id = 1; -- 第二次读aa
commit;
```

串行化不用解释了，依次执行，不会产生冲突。
**可重复读**是什么意思呢？ 事务2执行到一半时，事务1 成功提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**幻读**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是一样的，对刚更新的值不可见，隔离已经存在的数据。 可以重复读，读到的数据都是一样的。

**读取已提交**是什么意思呢？ 事务2执行到一半时，事务1 成功提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**幻读**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是不一样的，对刚提交的值可见，不隔离已经存在的数据。 不可以重复读，读到的数据是不一样的(如果成功修改)。

**读取未提交**是什么意思呢？ 事务2执行到一半时，事务1 还未提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**幻读**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是不一样的（事务1未提交），对最新版本的值可见，不隔离已经存在的数据。 不可以重复读，读到的数据是不一样的。
- 如果此时事务1因为其他原因回滚了，事务2第二次读到的数据是无意义的，因为修改没有发生(回滚了)，这叫**脏读** 。

在现实环境中，串行化一般不会被使用，因为性能太低。

如果对一致性有要求，比如转账交易，那么要使用可重复读，并发性能相对较差。 原因是，为了实现可重复读，在对更新记录加锁时，除了使用记录锁，还可能会使用`间隙锁`锁住区间(看update语句的where条件)，这会增加其他事务等待时间。

如果对一致性要求不高，一般使用读取已提交, 由于不考虑重复读，在加锁时一般只加记录锁，不会使用间隙锁，并发性较好，据说使用的最多。

## 如何保证持久性

隔离性的问题解决了，但是如果在事务提交后，事务的数据还没有真正落到磁盘上，此时数据库奔溃了，事务对应的数据会不会丢？

事务会保证数据不会丢，当数据库因不可抗拒的原因奔溃后重启，它会保证：

- 成功提交的事务，数据会保存到磁盘
- 未提交的事务，相应的数据会回滚

## 事务日志

数据库通过事务日志来达到这个目标。 事务的每一个操作（增/删/改）产生一条日志，内容组成大概如下：

- LSN：一个按时间顺序分配的唯一日志序列号，靠后的操作的LSN比靠前的大。
- TransID：产生操作的事务ID。
- PageID：被修改的数据在磁盘上的位置，数据以页为单位存储。
- PrevLSN：同一个事务产生的上一条日志记录的指针。
- UNDO：取消本次操作的方法，按照此方法回滚。
- REDO：重复本次操作的方法，如有必要，重复此方法保证操作成功。

![](https://niuzhan-1306014148.cos.ap-beijing.myqcloud.com/Typora/image-20200518160953706.png)

磁盘上每个页（保存数据的，不是保存日志的）都记录着最后一个修改该数据操作的LSN。数据库会通过解析事务日志，将修改真正落到磁盘上(写盘)，随后清理事务日志(正常情况下)。

这也是数据库在保证`数据安全`和`性能`这两个点之前的折中办法：

- 如果每次更新都写盘，由于数据是随机的，会造成大量的随机IO，性能会非常差
- 如果每次更新不马上写盘，那一旦数据库崩溃，数据就会丢失

折中的办法就是：

- 将数据的变更以事务日志的方式，按照时间先后追加到日志缓冲区，由特定算法写入事务日志，这是顺序IO，性能较好
- 通过数据管理器解析事务日志，由特定的算法择机进行写盘

## 数据库恢复

当数据库从崩溃中恢复时，会有以下几个步骤：

- 解析存在的事务日志，分析哪些事务需要回滚，哪些需要写盘(还没来得及写盘，数据库就崩溃了)。
- Redo，进行写盘。检测对应数据所在数据页的LSN，如果数据页的LSN>=事务操作的LSN，说明已经写过盘，不然进行写盘操作。
- Undo, 按照LSN倒序进行回滚

经过这几个阶段，在数据库恢复后，可以达到奔溃前的状态，也保证了数据的一致性。

> 摘自https://zhuanlan.zhihu.com/p/43493165



# MySQL索引

> 索引是存储引擎用于快速找到记录的一种数据结构

这是MySQL官方对于索引的定义，可以看到索引是一种数据结构，那么该怎样理解索引呢？比如说书的目录，我们拿到一本书时，我们首先会查看他的目录，并且当我们要查找某个内容时，我们会在目录中查找，然后找到该片段对应的页码，在根据响应的页码去书中查找，如果没有索引（目录），我们就只能一页一页的去查找了。

## 索引的优点

- 减少查询需要扫描的数据量（加快了查询速度）
- 减少服务器的排序操作和创建临时表的操作（加快了groupby和orderby等操作）
- 将服务器的随机IO变为舒徐IO（加快查询速度）

## 索引的缺点

首先索引也是数据，也需要存储，因此会带来额外的存储空间占用，其次，在插入、更新和删除操作的同时，需要维护索引，因此会带来额外的时间开销

- 索引占用磁盘或者内存空间
- 减慢了插入更新操作的速度

实际上，在一定数据范围内（索引没有超级多的情况下），建立索引带来的开销是远远小于它带来的好处的，但是我们仍然要防止索引的滥用。

## 添加索引

```shell
alter table tbl_name add key(字段名);
```

### 对比

准备两张表，并且数据相同

先创建一个大文件，从1到1000万，总共占用一千万行

```shell
[root@localhost mysql]# seq 1 10000000 > /tmp/bigfile
[root@localhost mysql]# du -sh /tmp/bigfile 
76M /tmp/bigfile
```

创建两个相同的表

```shell
mysql> create table tb1(id int(10));
Query OK, 0 rows affected (0.01 sec)

mysql> desc tb1;
+-------+---------+------+-----+---------+-------+
| Field | Type    | Null | Key | Default | Extra |
+-------+---------+------+-----+---------+-------+
| id    | int(10) | YES  |     | NULL    |       |
+-------+---------+------+-----+---------+-------+
1 row in set (0.01 sec)

mysql> create table tb2(id int(10));
Query OK, 0 rows affected (0.01 sec)

mysql> desc tb2;
+-------+---------+------+-----+---------+-------+
| Field | Type    | Null | Key | Default | Extra |
+-------+---------+------+-----+---------+-------+
| id    | int(10) | YES  |     | NULL    |       |
+-------+---------+------+-----+---------+-------+
1 row in set (0.00 sec)
```

然后把刚刚创建的文件上传到两个表里

```shell
mysql> load data infile '/tmp/bigfile' into table db1.tb1;
Query OK, 10000000 rows affected (41.67 sec)
Records: 10000000  Deleted: 0  Skipped: 0  Warnings: 0
mysql> load data infile '/tmp/bigfile' into table tb2;
Query OK, 10000000 rows affected (38.00 sec)
Records: 10000000  Deleted: 0  Skipped: 0  Warnings: 0
mysql> select count(*) from tb1;
+----------+
| count(*) |
+----------+
| 10000000 |
+----------+
1 row in set (4.68 sec)

mysql> select count(*) from tb2;
+----------+
| count(*) |
+----------+
| 10000000 |
+----------+
1 row in set (4.42 sec)
```

可以看到tb1和tb2的表都有一千万行的数据。然后查询时间都是比较久的

接着给tb1表添加索引，然后在查询，可以看到明显有索引的，查询速度显著提升

```shell
mysql> alter table tb1 add key(id);
Query OK, 0 rows affected (22.33 sec)
Records: 0  Duplicates: 0  Warnings: 0

// 索引添加完成后，会在key列，添加值
mysql> desc tb1;
+-------+---------+------+-----+---------+-------+
| Field | Type    | Null | Key | Default | Extra |
+-------+---------+------+-----+---------+-------+
| id    | int(10) | YES  | MUL | NULL    |       |
+-------+---------+------+-----+---------+-------+
1 row in set (0.04 sec)

mysql> select * from tb1 where id='10000';
+-------+
| id    |
+-------+
| 10000 |
+-------+
1 row in set (0.01 sec)

mysql> select * from tb2 where id='10000';
+-------+
| id    |
+-------+
| 10000 |
+-------+
1 row in set (4.91 sec)
```

## 唯一索引

```
unique
```

普通索引允许被索引的数据列包含重复的值。比如说，因为人有可能同名，所以同一个姓名在同一个“员工个人资料”数据表里可能出现两次或更多次。

如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字`unique`把它定义为一个唯一索引。

优点：

- 简化了MySQL对这个索引的管理工作，这个索引也因此而变得更有效率
- MySQL会在有新记录插入数据表时，自动检查新记录的这个字段的值是否已经在某个记录的这个字段里出现过；如果是，MySQL将拒绝插入这条新记录。

也就是说，唯一索引可以保证数据记录的唯一性。事实上，在许多场合，人们创建唯一索引的目的不是为了提供访问速度，而是为了避免数据重复。

## 测试

创建一个唯一索引的表

```shell
mysql> create table tb3(id int unique);
Query OK, 0 rows affected (0.04 sec)

mysql> desc tb3;
+-------+---------+------+-----+---------+-------+
| Field | Type    | Null | Key | Default | Extra |
+-------+---------+------+-----+---------+-------+
| id    | int(11) | YES  | UNI | NULL    |       |
+-------+---------+------+-----+---------+-------+
1 row in set (0.03 sec)
```

然后插入数据查看，可以看到插入100的值，只能插入一次

```shell
mysql> insert into tb3 values(100);
Query OK, 1 row affected (0.03 sec)

mysql> insert into tb3 values(100);
ERROR 1062 (23000): Duplicate entry '100' for key 'id'
```

## Auto_increment自动增长列

MySQL中的`auto_increment`类型属性用于为一个表中记录自动生成ID功能。可在一定程度上代替Orale、PostgreSQL等数据中的sequence。

可以在建表时用`auto_increment=n`选项来指定一个自增的初始值

可用`alter table tbl_name auto_increment=n`命令来重设自增的起始值。

当插入记录时，如果为`auto_increment`数据库列明确指定了一个数值，则会出现两种情况

- 如果插入的值与已有的编号重复，则会出现报错，因为`auto_increment`数据列的值必须是唯一的；
- 如果插入的值大于已编号的值，则会把该值插入到数据列中，并使在一个编号将从这个新值开始递增。也就是说，可以跳过一些编号。

如果自增序列的最大值被删除了，则在插入新记录时，该值被重用。

如果用update命令更新自增列，如果列值与已有的值重复，则会出错。如果大于已有值，则下一个编号从该值开始递增。

## 使用auto_increment时，应注意以下几点：

- `auto_increment`是数据列的一种属性，只适用于整数类型的数据列
- 对于InnoDB表，自动增长列必须是索引，切必须是组合索引的第一列，且一个表只能有一个`auto_increment`属性。
- 设置`auto_increment`属性的数据列应该是一个正数序列，所以应该把该数据列声明为`unsigned`，这样序列的编号个数可增加一倍
- `auto_increment`数据列必须有唯一索引（unique），以避免序号重复（即是主键或者主键的一部分）
- `auto_increment`数据列必须具备`not null`属性
- `auto_increment`数据列序号的最大值受该列的数据类型约束，如`tinyint`数据列的最大编号是127，如加上`unsigned`，则最大为255。一旦达到上限，`auto_increment`就会失效
- 当进行全表删除时，MySQL auto_increment会从1重新开始编号。

### 测试

创建一个表，id列是唯一索引的自增列

```shell
mysql> create table tb4(id int unique auto_increment,name char(10));
Query OK, 0 rows affected (0.06 sec)

mysql> desc tb4;
+-------+----------+------+-----+---------+----------------+
| Field | Type     | Null | Key | Default | Extra          |
+-------+----------+------+-----+---------+----------------+
| id    | int(11)  | NO   | PRI | NULL    | auto_increment |
| name  | char(10) | YES  |     | NULL    |                |
+-------+----------+------+-----+---------+----------------+
2 rows in set (0.01 sec)
```

然后插入一条语句，指定name=zhangsan，可以看到id列自动填写为1

```shell
mysql> insert into tb4(name) values('zhangsan');
Query OK, 1 row affected (0.00 sec)

mysql> select * from tb4;
+----+----------+
| id | name     |
+----+----------+
|  1 | zhangsan |
+----+----------+
1 row in set (0.00 sec)
```

接着重复的插入zhangsan，可以看到id列的值是自动增加的

```shell
mysql> insert into tb4(name) values('zhangsan');
Query OK, 1 row affected (0.01 sec)

mysql> insert into tb4(name) values('zhangsan');
Query OK, 1 row affected (0.00 sec)

mysql> insert into tb4(name) values('zhangsan');
Query OK, 1 row affected (0.01 sec)

mysql> select * from tb4;
+----+----------+
| id | name     |
+----+----------+
|  1 | zhangsan |
|  2 | zhangsan |
|  3 | zhangsan |
|  4 | zhangsan |
+----+----------+
4 rows in set (0.00 sec)
```



# MySQL锁机制

锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是MySQL在服务器层和存储引擎层的并发控制。

加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否已接触、释放锁等。

## 两种锁机制

- 读锁：其他事务可以度，但不能写
- 写锁：其他事务不能读取，也不能写

MySQL不同的存储引擎支持不通的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现

- MyISAM和MEMORY存储引擎采用的是表级锁（table-level lockng）
- BDB存储引擎采用的是页面所（page-level locking），但也支持表级锁
- InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁

默认情况下，表锁和行锁都是自动获得的，不需要额外的命令。

但是在有的情况下，用户需要明确地进行锁表或者进行事务的控制，以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。

## 不同锁的比较

- **表级锁**：开销小，加锁快，不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
  - 这些存储引擎通过总是一次行同时获取所有需要的锁以及总是按相同的顺序回去表锁来避免死锁。
  - 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如web应用
- **行级锁**：开销大，加锁慢；会出现死锁；锁定力度小，发生锁冲突的概率最低，并发度也最高。
  - 最大成都的支持并发，同时也带来了最大的锁开销。
  - 在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了在InnoDB中发生死锁是可能的。
  - 行级锁只在存储引擎层实现，而MySQL服务器层没有实现。行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统
- 页面锁：开销和加锁时间介于表锁和行锁之间；会出现死锁；锁定力度介于表锁和行锁之间，并发度一般。

## 加锁

```
lock table tbl_name write/read;
```

## 解锁

```
unlock tables;
```



